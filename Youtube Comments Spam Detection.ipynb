{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "399fef4e",
   "metadata": {},
   "source": [
    "<h1>Youtube Comments Spam Detection</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b1846c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdcec73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/kevin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading Stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "938a930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting api_key from environment variable\n",
    "load_dotenv()\n",
    "api_key = os.getenv('api_key')\n",
    "\n",
    "# Creating build object for Youtube\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "262d4145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_ids(youtube, playlist_id):\n",
    "    video_ids = []\n",
    "    \n",
    "    request = youtube.playlistItems().list(\n",
    "        part='contentDetails',\n",
    "        playlistId=playlist_id,\n",
    "        maxResults = 50\n",
    "    )\n",
    "    \n",
    "    response = request.execute()\n",
    "    \n",
    "    for item in response['items']:\n",
    "        video_ids.append(item['contentDetails']['videoId'])\n",
    "        \n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    \n",
    "    while next_page_token is not None:\n",
    "        request = youtube.playlistItems().list(\n",
    "            part='contentDetails',\n",
    "            playlistId = playlist_id,\n",
    "            maxResults = 50,\n",
    "            pageToken = next_page_token\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        for item in response['items']:\n",
    "            video_ids.append(item['contentDetails']['videoId'])\n",
    "            \n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        \n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b982c6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlists(youtube, channel_ids):\n",
    "    upload_playlists = []\n",
    "    \n",
    "    request = youtube.channels().list(\n",
    "        part='contentDetails',\n",
    "        id=','.join(channel_ids)\n",
    "    )\n",
    "    \n",
    "    response = request.execute()\n",
    "    \n",
    "    for item in response['items']:\n",
    "        upload_playlists.append(item['contentDetails']['relatedPlaylists']['uploads'])\n",
    "        \n",
    "    return upload_playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e969165e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments_in_videos(youtube, video_ids):\n",
    "    comments = np.array([])\n",
    "    \n",
    "    for video_id in video_ids:\n",
    "        request = youtube.commentThreads().list(\n",
    "            part='snippet,replies',\n",
    "            videoId=video_id,\n",
    "            order = 'time',\n",
    "            maxResults = 100\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        comments_in_video = [\n",
    "            comment['snippet']['topLevelComment']['snippet']['textOriginal']\n",
    "            for comment in response['items']\n",
    "        ]\n",
    "        comments = np.append(comments, comments_in_video)\n",
    "        \n",
    "        while response:   \n",
    "            comments_in_video = [\n",
    "                comment['snippet']['topLevelComment']['snippet']['textOriginal']\n",
    "                for comment in response['items']\n",
    "            ]\n",
    "            comments = np.append(comments, comments_in_video)\n",
    "            \n",
    "            if 'nextPageToken' in response:\n",
    "                request = youtube.commentThreads().list(\n",
    "                    part='snippet,replies',\n",
    "                    videoId=video_id,\n",
    "                    order = 'time',\n",
    "                    maxResults = 100,\n",
    "                    pageToken=response['nextPageToken']\n",
    "                )\n",
    "                response = request.execute()\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "            if len(set(comments)) > 2000:\n",
    "                break\n",
    "                \n",
    "    return list(set(comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa8a5ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processes and tokenizes the text\n",
    "def process_text(text): \n",
    "    out = re.sub(r'[^\\w\\s]', '', text) # Removing Punctuation\n",
    "    out = [word for word in out.split() if word.lower() not in stopwords.words('english')] # Removes Stopwords\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "97ba50be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting upload playlist from channel_id\n",
    "channel_ids = [\n",
    "    'UCX6OQ3DkcsbYNE6H8uQQuVA', # MrBeast\n",
    "    'UCoOjH8D2XAgjzQlneM2W0EQ', # JakeTran\n",
    "    'UCgv4dPk_qZNAbUW9WkuLPSA', # Atrioc\n",
    "    'UCYzPXprvl5Y-Sf0g4vX-m6g', # Jacksepticeye\n",
    "    'UCBJycsmduvYEL83R_U4JriQ'  # Marques Brownlee\n",
    "]\n",
    "playlists = get_playlists(youtube, channel_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "0a80acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all video ids for each Youtuber\n",
    "jacksepticeye_video_ids = get_video_ids(youtube, playlists[0])\n",
    "mr_beast_video_ids = get_video_ids(youtube, playlists[1])\n",
    "marques_brownlee_video_ids = get_video_ids(youtube, playlists[2])\n",
    "jake_tran_video_ids = get_video_ids(youtube, playlists[3])\n",
    "atrioc_video_ids = get_video_ids(youtube, playlists[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "6f210e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Jacksepticeye Videos:  4979\n",
      "Number of MrBeast Videos:  723\n",
      "Number of Marques Brownlee Videos:  1449\n",
      "Number of Jake Tran Videos:  203\n",
      "Number of Atrioc Videos:  615\n"
     ]
    }
   ],
   "source": [
    "# Number of videos for each Youtuber\n",
    "print('Number of Jacksepticeye Videos: ', len(jacksepticeye_video_ids))\n",
    "print('Number of MrBeast Videos: ', len(mr_beast_video_ids))\n",
    "print('Number of Marques Brownlee Videos: ', len(marques_brownlee_video_ids))\n",
    "print('Number of Jake Tran Videos: ', len(jake_tran_video_ids))\n",
    "print('Number of Atrioc Videos: ', len(atrioc_video_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "id": "b6f23c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only getting roughly at most 2000 comments from Youtuber's Latest Video\n",
    "jacksepticeye_comments = get_comments_in_videos(youtube, [jacksepticeye_video_ids[0]])\n",
    "mr_beast_comments = get_comments_in_videos(youtube, [mr_beast_video_ids[0]])\n",
    "marques_brownlee_comments = get_comments_in_videos(youtube, [marques_brownlee_video_ids[0]])\n",
    "jake_tran_comments = get_comments_in_videos(youtube, [jake_tran_video_ids[1]])\n",
    "atrioc_comments = get_comments_in_videos(youtube, [atrioc_video_ids[1]])\n",
    "# At the time, Jake Tran and Atrioc's Latest Video just came out so decided to use second latest video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "id": "e8c928fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combing all comments\n",
    "combined_comments = (\n",
    "    jacksepticeye_comments +\n",
    "    mr_beast_comments + \n",
    "    marques_brownlee_comments + \n",
    "    jake_tran_comments +\n",
    "    atrioc_comments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "f0e1e1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cats can eat grass it helps them when there st...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can't wait for Part 2 on this :D look's awes...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Its okay about the poncho Jack, you return to ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jack you forgot to find the first few memory s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I really hope Jack plays Sky some day, I reall...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7982</th>\n",
       "      <td>Forgot Paper Mario, classic mistake</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7983</th>\n",
       "      <td>what?!?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7984</th>\n",
       "      <td>I was not ready for him stabbing himself</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7985</th>\n",
       "      <td>I love the sound of falling onto a window in M...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7986</th>\n",
       "      <td>Fallout NV gotta be my GOAT game if i really h...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7987 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  is_spam\n",
       "0     Cats can eat grass it helps them when there st...      NaN\n",
       "1     I can't wait for Part 2 on this :D look's awes...      NaN\n",
       "2     Its okay about the poncho Jack, you return to ...      NaN\n",
       "3     Jack you forgot to find the first few memory s...      NaN\n",
       "4     I really hope Jack plays Sky some day, I reall...      NaN\n",
       "...                                                 ...      ...\n",
       "7982                Forgot Paper Mario, classic mistake      NaN\n",
       "7983                                            what?!?      NaN\n",
       "7984           I was not ready for him stabbing himself      NaN\n",
       "7985  I love the sound of falling onto a window in M...      NaN\n",
       "7986  Fallout NV gotta be my GOAT game if i really h...      NaN\n",
       "\n",
       "[7987 rows x 2 columns]"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial Setup of Comments DataFrame\n",
    "youtube_comments = pd.DataFrame(\n",
    "    data = {'comment': combined_comments, 'is_spam': [np.nan for i in range(len(combined_comments))]}\n",
    ")\n",
    "youtube_comments.to_csv('youtube_comments.csv', index = False)\n",
    "youtube_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6b3e4b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That intro was commercial level\n",
      "0\n",
      "So anybody noticed the tape at the beginning where MKB placed the laptop.\n",
      "0\n",
      "Love your reviews! Hope you can also compare the m2 air vs the m1 pro 14 both at 516gb\n",
      "0\n",
      "Hear me out: if you want a thin and light but a more powerful option at home, maybe some external cooling would suffice? A passive cooling block/stand or a fan cooled base + a second monitor and keyboard & mouse.\n",
      "@LTT should definitely try this out!\n",
      "0\n",
      "Now if they only made it in a larger form factor with a larger battery and screen...\n",
      "0\n",
      "M1 16GB vs M2 8GB for video editing ?\n",
      "0\n",
      "Buy a silver one and pack it with dbrand skin 👌\n",
      "0\n",
      "😍\n",
      "0\n",
      "Love how direct and easily explained this video is\n",
      "0\n",
      "that intro is sick. woow,  just wow. what a shot\n",
      "0\n",
      "the intro 💯\n",
      "0\n",
      "Actually the scratchiness of the dark MacBooks persists for years now. I have some dark MacBooks which are scratched all over the place with daily use of their usb-c ports. So I think it is not so new problem\n",
      "0\n",
      "I don't know what's in the video but intro was man o man dope\n",
      "0\n",
      "That intro was goood!!!\n",
      "0\n",
      "New to your channel (youtube recommended) and loving the content and quality of it! Thanks for the valuable info!\n",
      "0\n",
      "I’m still rocking my M1 MacBook Air (2020) for video editing at 4k and still does the job right 🫡\n",
      "0\n",
      "Awesome content mate, keep up the great work. where can I get that wallpapers?\n",
      "0\n",
      "Where did you find this wallpaper?\n",
      "0\n",
      "I wish could by this laptop 💻 😪\n",
      "0\n",
      "Wallpaper link please\n",
      "0\n",
      "You can’t hold onto the 999$ price point forever bro, inflation in the last few years has been crazy. I’m surprised they could even hold the price down.\n",
      "0\n",
      "Haven't even started the video but THAT INTROOOOOOOOOOOOOOOOOOOOOOO\n",
      "0\n",
      "compare it with MBA M1??\n",
      "0\n",
      "I have to say, I love you man! And let me explain why! \n",
      "\n",
      "I’ve watched countless reviews on this laptop and I have not come across a single one mentioning what you are doing in terms of an upgraded M2 air vs M1 14 Pro. I’m currently looking to get an M2 air with 16GB memory and 512GB storage for normal daily use, that’s $2499 AUD here in Australia. On the other hand, the base model M1 14 Pro is currently retailing at $2999 AUD with frequent discounts being as low as $2697 AUD on Amazon Australia (atm). That small little extra cost is not a whole lot compared to the huge increase in preference you get by choosing the M1 14 Prob in my case. \n",
      "\n",
      "But I guess you’re right, that’s how Apple gets you to spend that extra money that you weren’t planning on doing from the beginning.. 🤷🏻‍♂️😂\n",
      "0\n",
      "macbook pro needs that color\n",
      "0\n",
      "SICK INTRO\n",
      "0\n",
      "You gotta remember though. They want to sell the air AND the pro. There has to be a difference between the two, you can’t get the ports, the screen, the brightness, in the air that the pro has, cause then the pro would be a pointless laptop. It’s good business bad customer service\n",
      "0\n",
      "What's the wallpaper?\n",
      "0\n",
      "Maybe they assumed they could get away with the significantly higher price due to the success of the M1\n",
      "0\n",
      "Daymm I also made the Webb space image as my Mac wallpaper 😂😂😂\n",
      "0\n",
      "I ain't watching any more vids with facemasks on.\n",
      "0\n",
      "the intro is getting simpler over time\n",
      "0\n",
      "How to install windows on that thing?\n",
      "0\n",
      "mkbhd is now obsessed with that wallpaper\n",
      "0\n",
      "It is pretty great video!\n",
      "0\n",
      "Bullshit product\n",
      "0\n",
      "where is the wallpaper i only can find low quality ones\n",
      "0\n",
      "Slick intro!\n",
      "0\n",
      "😳\n",
      "0\n",
      "wow that intro si worth a million\n",
      "0\n",
      "This new Air is really disappointing. It offers nothing special, has thermal problems, has crappier SSD and it's iconic shape is gone to look just like a thinner MacBook Pro. Apple couldn't be lazier here.\n",
      "0\n",
      "Disappointing. Why didn't you or a phone next to the laptop so we can see how thin it is. \n",
      "\n",
      "Others didn't, was going you would.\n",
      "0\n",
      "so basically for someone like me who does a lot of work in blender/the adobe suite…the pro would be a better option 😳\n",
      "0\n",
      "These intros are getting sexier and sexier\n",
      "0\n",
      "That intro!!!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Labeling Comments if Spam or Not\n",
    "youtube_comment_temp = pd.read_csv('youtube_comments.csv')\n",
    "for i in range(youtube_comment_temp.shape[0]):\n",
    "    if np.isnan(youtube_comment_temp['is_spam'].iloc[i]):\n",
    "        print(youtube_comment_temp.iloc[i]['comment'])\n",
    "        is_spam = input()\n",
    "        if is_spam in ['0', '1']:\n",
    "            youtube_comment_temp['is_spam'].iloc[i] = is_spam\n",
    "        elif is_spam in ['2']:\n",
    "            youtube_comment_temp['is_spam'].iloc[i] = 2\n",
    "        else:\n",
    "            break\n",
    "youtube_comment_temp.to_csv('youtube_comments.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "550a42c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cats can eat grass it helps them when there st...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can't wait for Part 2 on this :D look's awes...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Its okay about the poncho Jack, you return to ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jack you forgot to find the first few memory s...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I really hope Jack plays Sky some day, I reall...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7983</th>\n",
       "      <td>Forgot Paper Mario, classic mistake</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7984</th>\n",
       "      <td>what?!?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7985</th>\n",
       "      <td>I was not ready for him stabbing himself</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7986</th>\n",
       "      <td>I love the sound of falling onto a window in M...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7987</th>\n",
       "      <td>Fallout NV gotta be my GOAT game if i really h...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7988 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  is_spam\n",
       "0     Cats can eat grass it helps them when there st...      0.0\n",
       "1     I can't wait for Part 2 on this :D look's awes...      0.0\n",
       "2     Its okay about the poncho Jack, you return to ...      0.0\n",
       "3     Jack you forgot to find the first few memory s...      0.0\n",
       "4     I really hope Jack plays Sky some day, I reall...      0.0\n",
       "...                                                 ...      ...\n",
       "7983                Forgot Paper Mario, classic mistake      NaN\n",
       "7984                                            what?!?      NaN\n",
       "7985           I was not ready for him stabbing himself      NaN\n",
       "7986  I love the sound of falling onto a window in M...      NaN\n",
       "7987  Fallout NV gotta be my GOAT game if i really h...      NaN\n",
       "\n",
       "[7988 rows x 2 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data = pd.read_csv('youtube_comments.csv')\n",
    "labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "80652798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4871"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of valid data\n",
    "sum(labeled_data['is_spam'] < 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b9bb42cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of \"invalid\" data, where invalid is gibberish or non-english\n",
    "labeled_data[labeled_data['is_spam'] == 2].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "78e3518f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4600"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Not-Spam\n",
    "labeled_data[labeled_data['is_spam'] == 0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e30e8aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Spam\n",
    "labeled_data[labeled_data['is_spam'] == 1].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfd8611",
   "metadata": {},
   "source": [
    "To get more data for spam comments, I utilized the UCI Machine Learning Repository to gather more spam comments.\n",
    "https://archive.ics.uci.edu/ml/datasets/YouTube+Spam+Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0ec902b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data from UCI Machine Learning Repository\n",
    "psy_data = pd.read_csv('YouTube-Spam-Collection-v1/Youtube01-Psy.csv')[['CONTENT', 'CLASS']]\n",
    "katy_perry_data = pd.read_csv('YouTube-Spam-Collection-v1/Youtube02-KatyPerry.csv')[['CONTENT', 'CLASS']]\n",
    "lmfao_data = pd.read_csv('YouTube-Spam-Collection-v1/Youtube03-LMFAO.csv')[['CONTENT', 'CLASS']]\n",
    "eminem_data = pd.read_csv('YouTube-Spam-Collection-v1/Youtube04-Eminem.csv')[['CONTENT', 'CLASS']]\n",
    "shakira_data = pd.read_csv('YouTube-Spam-Collection-v1/Youtube05-Shakira.csv')[['CONTENT', 'CLASS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b39b6278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>********OMG Facebook is OLD! Check out  ------...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Hey Music Fans I really appreciate all of you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>**CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>**CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>**CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1005 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment  is_spam\n",
       "0    Huh, anyway check out this you[tube] channel: ...        1\n",
       "1    Hey guys check out my new channel and our firs...        1\n",
       "2               just for test I have to say murdev.com        1\n",
       "3     me shaking my sexy ass on my channel enjoy ^_^ ﻿        1\n",
       "4              watch?v=vtaRGgvGtWQ   Check this out .﻿        1\n",
       "..                                                 ...      ...\n",
       "357  ********OMG Facebook is OLD! Check out  ------...        1\n",
       "358  Hey Music Fans I really appreciate all of you ...        1\n",
       "359  **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...        1\n",
       "360  **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...        1\n",
       "361  **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...        1\n",
       "\n",
       "[1005 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat all spam comments, standardizing column names, filter only spam comments\n",
    "spam_data = pd.concat([psy_data, katy_perry_data, lmfao_data, eminem_data, shakira_data])\n",
    "spam_comments = spam_data.rename(columns={'CONTENT':'comment', 'CLASS':'is_spam'})[spam_data['CLASS'] == 1]\n",
    "spam_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30279f2d",
   "metadata": {},
   "source": [
    "<h2>Creating Spam Detection ML Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9de5bf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cats can eat grass it helps them when there st...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can't wait for Part 2 on this :D look's awes...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Its okay about the poncho Jack, you return to ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jack you forgot to find the first few memory s...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I really hope Jack plays Sky some day, I reall...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>********OMG Facebook is OLD! Check out  ------...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Hey Music Fans I really appreciate all of you ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>**CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>**CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>**CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4065 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment  is_spam\n",
       "0    Cats can eat grass it helps them when there st...      0.0\n",
       "1    I can't wait for Part 2 on this :D look's awes...      0.0\n",
       "2    Its okay about the poncho Jack, you return to ...      0.0\n",
       "3    Jack you forgot to find the first few memory s...      0.0\n",
       "4    I really hope Jack plays Sky some day, I reall...      0.0\n",
       "..                                                 ...      ...\n",
       "357  ********OMG Facebook is OLD! Check out  ------...      1.0\n",
       "358  Hey Music Fans I really appreciate all of you ...      1.0\n",
       "359  **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...      1.0\n",
       "360  **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...      1.0\n",
       "361  **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...      1.0\n",
       "\n",
       "[4065 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = pd.concat([labeled_data[labeled_data['is_spam'] < 2], spam_comments]).dropna()\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8e499033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to matrix of token counts\n",
    "bag_of_words = CountVectorizer(analyzer=process_text).fit_transform(filtered_data['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "378ca7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    bag_of_words,\n",
    "    filtered_data['is_spam'],\n",
    "    test_size = 0.3,\n",
    "    random_state = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "863876fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and training Naive Bayes Classifier\n",
    "classifier = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e2f29e",
   "metadata": {},
   "source": [
    "<h2>Evaluating Model on Training Data Set</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7b5dfdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      2069\n",
      "         1.0       0.96      0.98      0.97       776\n",
      "\n",
      "    accuracy                           0.98      2845\n",
      "   macro avg       0.97      0.98      0.98      2845\n",
      "weighted avg       0.98      0.98      0.98      2845\n",
      "\n",
      "Confusion matrix: \n",
      " [[2034   35]\n",
      " [  15  761]] \n",
      "\n",
      "Accuracy: \n",
      " 0.9824253075571178\n"
     ]
    }
   ],
   "source": [
    "pred_train = classifier.predict(X_train)\n",
    "print('Classification Report: \\n', classification_report(y_train, pred_train))\n",
    "print('Confusion matrix: \\n', confusion_matrix(y_train, pred_train), '\\n')\n",
    "print('Accuracy: \\n', accuracy_score(y_train, pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa6a02b",
   "metadata": {},
   "source": [
    "<h2>Evaluating Model on Test Data Set</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "16f1c888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.95       882\n",
      "         1.0       0.87      0.85      0.86       338\n",
      "\n",
      "    accuracy                           0.92      1220\n",
      "   macro avg       0.91      0.90      0.90      1220\n",
      "weighted avg       0.92      0.92      0.92      1220\n",
      "\n",
      "Confusion matrix: \n",
      " [[840  42]\n",
      " [ 52 286]] \n",
      "\n",
      "Accuracy: \n",
      " 0.9229508196721311\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Model on training data set\n",
    "pred_test = classifier.predict(X_test)\n",
    "print('Classification Report: \\n', classification_report(y_test, pred_test))\n",
    "print('Confusion matrix: \\n', confusion_matrix(y_test, pred_test), '\\n')\n",
    "print('Accuracy: \\n', accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9df644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

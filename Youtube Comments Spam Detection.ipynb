{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b81b1b0",
   "metadata": {},
   "source": [
    "<h1>Youtube Comments Spam Detection</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "a400f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "800f15a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/kevin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading Stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44f8ef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting api_key from environment variable\n",
    "load_dotenv()\n",
    "api_key = os.getenv('api_key')\n",
    "\n",
    "# Creating build object for Youtube\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "08e19bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_ids(youtube, playlist_id):\n",
    "    video_ids = []\n",
    "    \n",
    "    request = youtube.playlistItems().list(\n",
    "        part='contentDetails',\n",
    "        playlistId=playlist_id,\n",
    "        maxResults = 50\n",
    "    )\n",
    "    \n",
    "    response = request.execute()\n",
    "    \n",
    "    for item in response['items']:\n",
    "        video_ids.append(item['contentDetails']['videoId'])\n",
    "        \n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    \n",
    "    while next_page_token is not None:\n",
    "        request = youtube.playlistItems().list(\n",
    "            part='contentDetails',\n",
    "            playlistId = playlist_id,\n",
    "            maxResults = 50,\n",
    "            pageToken = next_page_token\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        for item in response['items']:\n",
    "            video_ids.append(item['contentDetails']['videoId'])\n",
    "            \n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        \n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "31cea51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlists(youtube, channel_ids):\n",
    "    upload_playlists = []\n",
    "    \n",
    "    request = youtube.channels().list(\n",
    "        part='contentDetails',\n",
    "        id=','.join(channel_ids)\n",
    "    )\n",
    "    \n",
    "    response = request.execute()\n",
    "    \n",
    "    for item in response['items']:\n",
    "        upload_playlists.append(item['contentDetails']['relatedPlaylists']['uploads'])\n",
    "        \n",
    "    return upload_playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "2eee91c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments_in_videos(youtube, video_ids):\n",
    "    comments = np.array([])\n",
    "    \n",
    "    for video_id in video_ids:\n",
    "        request = youtube.commentThreads().list(\n",
    "            part='snippet,replies',\n",
    "            videoId=video_id,\n",
    "            order = 'time',\n",
    "            maxResults = 100\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        comments_in_video = [\n",
    "            comment['snippet']['topLevelComment']['snippet']['textOriginal']\n",
    "            for comment in response['items']\n",
    "        ]\n",
    "        comments = np.append(comments, comments_in_video)\n",
    "        \n",
    "        while response:   \n",
    "            comments_in_video = [\n",
    "                comment['snippet']['topLevelComment']['snippet']['textOriginal']\n",
    "                for comment in response['items']\n",
    "            ]\n",
    "            comments = np.append(comments, comments_in_video)\n",
    "            \n",
    "            if 'nextPageToken' in response:\n",
    "                request = youtube.commentThreads().list(\n",
    "                    part='snippet,replies',\n",
    "                    videoId=video_id,\n",
    "                    order = 'time',\n",
    "                    maxResults = 100,\n",
    "                    pageToken=response['nextPageToken']\n",
    "                )\n",
    "                response = request.execute()\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "            if len(set(comments)) > 10000:\n",
    "                break\n",
    "                \n",
    "    return list(set(comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "d6027c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processes and tokenizes the text\n",
    "def process_text(text): \n",
    "    out = re.sub(r'[^\\w\\s]', '', text) # Removing Punctuation\n",
    "    out = [word for word in out.split() if word.lower() not in stopwords.words('english')] # Removes Stopwords\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "bf111cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting upload playlist from channel_id\n",
    "channel_ids = [\n",
    "    'UCX6OQ3DkcsbYNE6H8uQQuVA', #MrBeast\n",
    "]\n",
    "playlists = get_playlists(youtube, channel_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "435c9974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all video ids from MrBeast\n",
    "mr_beast_video_ids = get_video_ids(youtube, mr_beast_playlist[0])\n",
    "\n",
    "# Only getting comments from MrBeast's Latest Video\n",
    "mr_beast_comments = get_comments_in_videos(youtube, [mr_beast_video_ids[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "05dee50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "723"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of MrBeast Videos\n",
    "len(mr_beast_video_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "de95f7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr beast, create the backrooms in real life</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mr. Beast is the world's famous as well as ide...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello sir \\nI am Sarvesh From India\\nI need 1k...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Only 1M please guys  you can do it</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i love you mrbeastðŸ˜»ðŸ˜»</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10051</th>\n",
       "      <td>Bro i send some, direct message on your legit ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10052</th>\n",
       "      <td>Hi mr beast you are my favorite YouTuber</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10053</th>\n",
       "      <td>Whereâ€™s karl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10054</th>\n",
       "      <td>You basically got a haircut no need for a hat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10055</th>\n",
       "      <td>Cool</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10056 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  is_spam\n",
       "0            Mr beast, create the backrooms in real life      NaN\n",
       "1      Mr. Beast is the world's famous as well as ide...      NaN\n",
       "2      Hello sir \\nI am Sarvesh From India\\nI need 1k...      NaN\n",
       "3                     Only 1M please guys  you can do it      NaN\n",
       "4                                   i love you mrbeastðŸ˜»ðŸ˜»      NaN\n",
       "...                                                  ...      ...\n",
       "10051  Bro i send some, direct message on your legit ...      NaN\n",
       "10052           Hi mr beast you are my favorite YouTuber      NaN\n",
       "10053                                       Whereâ€™s karl      NaN\n",
       "10054      You basically got a haircut no need for a hat      NaN\n",
       "10055                                               Cool      NaN\n",
       "\n",
       "[10056 rows x 2 columns]"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial Setup of Comments DataFrame\n",
    "youtube_comments = pd.DataFrame(\n",
    "    data = {'comment': mr_beast_comments[1:], 'is_spam': [np.nan for i in range(len(mr_beast_comments[1:]))]}\n",
    ")\n",
    "youtube_comments.to_csv('youtube_comments.csv', index = False)\n",
    "youtube_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "db84d8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ammogabs blog\n",
      "h\n"
     ]
    }
   ],
   "source": [
    "# Labeling Comments if Spam or Not\n",
    "youtube_comment_temp = pd.read_csv('youtube_comments.csv')\n",
    "for i in range(youtube_comments.shape[0]):\n",
    "    if np.isnan(youtube_comment_temp['is_spam'].iloc[i]):\n",
    "        print(youtube_comment_temp.iloc[i]['comment'])\n",
    "        is_spam = input()\n",
    "        if is_spam in ['0', '1']:\n",
    "            youtube_comment_temp['is_spam'].iloc[i] = is_spam\n",
    "        elif is_spam in ['2']:\n",
    "            youtube_comment_temp['is_spam'].iloc[i] = 2\n",
    "        else:\n",
    "            break\n",
    "youtube_comment_temp.to_csv('youtube_comments.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "99254e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr beast, create the backrooms in real life</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mr. Beast is the world's famous as well as ide...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello sir \\nI am Sarvesh From India\\nI need 1k...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Only 1M please guys  you can do it</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i love you mrbeastðŸ˜»ðŸ˜»</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10051</th>\n",
       "      <td>Bro i send some, direct message on your legit ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10052</th>\n",
       "      <td>Hi mr beast you are my favorite YouTuber</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10053</th>\n",
       "      <td>Whereâ€™s karl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10054</th>\n",
       "      <td>You basically got a haircut no need for a hat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10055</th>\n",
       "      <td>Cool</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10056 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  is_spam\n",
       "0            Mr beast, create the backrooms in real life      0.0\n",
       "1      Mr. Beast is the world's famous as well as ide...      0.0\n",
       "2      Hello sir \\nI am Sarvesh From India\\nI need 1k...      1.0\n",
       "3                     Only 1M please guys  you can do it      0.0\n",
       "4                                   i love you mrbeastðŸ˜»ðŸ˜»      0.0\n",
       "...                                                  ...      ...\n",
       "10051  Bro i send some, direct message on your legit ...      NaN\n",
       "10052           Hi mr beast you are my favorite YouTuber      NaN\n",
       "10053                                       Whereâ€™s karl      NaN\n",
       "10054      You basically got a haircut no need for a hat      NaN\n",
       "10055                                               Cool      NaN\n",
       "\n",
       "[10056 rows x 2 columns]"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data = pd.read_csv('youtube_comments.csv')\n",
    "labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "b1ec0f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of valid data\n",
    "sum(labeled_data['is_spam'] < 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "0331155b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of invalid data\n",
    "labeled_data[labeled_data['is_spam'] == 2].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "64d865ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "628"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Not-Spam\n",
    "labeled_data[labeled_data['is_spam'] == 0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "20007591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Spam\n",
    "labeled_data[labeled_data['is_spam'] == 1].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2411507e",
   "metadata": {},
   "source": [
    "Creating Spam Detection ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "abaab400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr beast, create the backrooms in real life</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mr. Beast is the world's famous as well as ide...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello sir \\nI am Sarvesh From India\\nI need 1k...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Only 1M please guys  you can do it</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i love you mrbeastðŸ˜»ðŸ˜»</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>You look good bald</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>Fianlly got a Verifted Bagdge</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>ME hungy</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>bruh i dont have a dog and a cat</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>Mrbeast did you know The brazillians have anot...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>695 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment  is_spam\n",
       "0          Mr beast, create the backrooms in real life      0.0\n",
       "1    Mr. Beast is the world's famous as well as ide...      0.0\n",
       "2    Hello sir \\nI am Sarvesh From India\\nI need 1k...      1.0\n",
       "3                   Only 1M please guys  you can do it      0.0\n",
       "4                                 i love you mrbeastðŸ˜»ðŸ˜»      0.0\n",
       "..                                                 ...      ...\n",
       "749                                 You look good bald      0.0\n",
       "750                      Fianlly got a Verifted Bagdge      0.0\n",
       "751                                           ME hungy      0.0\n",
       "752                   bruh i dont have a dog and a cat      0.0\n",
       "753  Mrbeast did you know The brazillians have anot...      0.0\n",
       "\n",
       "[695 rows x 2 columns]"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = labeled_data[labeled_data['is_spam'] < 2]\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "5d9f8d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to matrix of token counts\n",
    "bag_of_words = CountVectorizer(analyzer=process_text).fit_transform(filtered_data['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "e6dd9fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    bag_of_words,\n",
    "    filtered_data['is_spam'],\n",
    "    test_size = 0.3,\n",
    "    random_state = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "ba20017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and training Naive Bayes Classifier\n",
    "classifier = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd693b4",
   "metadata": {},
   "source": [
    "Evaluating Model on Training Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "695e723c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99       433\n",
      "         1.0       0.98      0.87      0.92        53\n",
      "\n",
      "    accuracy                           0.98       486\n",
      "   macro avg       0.98      0.93      0.96       486\n",
      "weighted avg       0.98      0.98      0.98       486\n",
      "\n",
      "Confusion matrix: \n",
      " [[432   1]\n",
      " [  7  46]]\n",
      "Accuracy: \n",
      " 0.9835390946502057\n"
     ]
    }
   ],
   "source": [
    "pred_train = classifier.predict(X_train)\n",
    "print('Classification Report: \\n', classification_report(y_train, pred_train))\n",
    "print('Confusion matrix: \\n', confusion_matrix(y_train, pred_train))\n",
    "print('Accuracy: \\n', accuracy_score(y_train, pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947926dc",
   "metadata": {},
   "source": [
    "Evaluating Model on Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "2612afc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.94      0.96       195\n",
      "         1.0       0.42      0.57      0.48        14\n",
      "\n",
      "    accuracy                           0.92       209\n",
      "   macro avg       0.69      0.76      0.72       209\n",
      "weighted avg       0.93      0.92      0.92       209\n",
      "\n",
      "Confusion matrix: \n",
      " [[184  11]\n",
      " [  6   8]]\n",
      "Accuracy: \n",
      " 0.9186602870813397\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Model on training data set\n",
    "pred_test = classifier.predict(X_test)\n",
    "print('Classification Report: \\n', classification_report(y_test, pred_test))\n",
    "print('Confusion matrix: \\n', confusion_matrix(y_test, pred_test))\n",
    "print('Accuracy: \\n', accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5c6429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

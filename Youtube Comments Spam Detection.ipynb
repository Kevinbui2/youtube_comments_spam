{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "399fef4e",
   "metadata": {},
   "source": [
    "<h1>Youtube Comments Spam Detection</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "9b1846c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "cdcec73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/kevin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading Stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "938a930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting api_key from environment variable\n",
    "load_dotenv()\n",
    "api_key = os.getenv('api_key')\n",
    "\n",
    "# Creating build object for Youtube\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "262d4145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_ids(youtube, playlist_id):\n",
    "    video_ids = []\n",
    "    \n",
    "    request = youtube.playlistItems().list(\n",
    "        part='contentDetails',\n",
    "        playlistId=playlist_id,\n",
    "        maxResults = 50\n",
    "    )\n",
    "    \n",
    "    response = request.execute()\n",
    "    \n",
    "    for item in response['items']:\n",
    "        video_ids.append(item['contentDetails']['videoId'])\n",
    "        \n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    \n",
    "    while next_page_token is not None:\n",
    "        request = youtube.playlistItems().list(\n",
    "            part='contentDetails',\n",
    "            playlistId = playlist_id,\n",
    "            maxResults = 50,\n",
    "            pageToken = next_page_token\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        for item in response['items']:\n",
    "            video_ids.append(item['contentDetails']['videoId'])\n",
    "            \n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        \n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b982c6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlists(youtube, channel_ids):\n",
    "    upload_playlists = []\n",
    "    \n",
    "    request = youtube.channels().list(\n",
    "        part='contentDetails',\n",
    "        id=','.join(channel_ids)\n",
    "    )\n",
    "    \n",
    "    response = request.execute()\n",
    "    \n",
    "    for item in response['items']:\n",
    "        upload_playlists.append(item['contentDetails']['relatedPlaylists']['uploads'])\n",
    "        \n",
    "    return upload_playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "id": "e969165e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments_in_videos(youtube, video_ids):\n",
    "    comments = np.array([])\n",
    "    \n",
    "    for video_id in video_ids:\n",
    "        request = youtube.commentThreads().list(\n",
    "            part='snippet,replies',\n",
    "            videoId=video_id,\n",
    "            order = 'time',\n",
    "            maxResults = 100\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        comments_in_video = [\n",
    "            comment['snippet']['topLevelComment']['snippet']['textOriginal']\n",
    "            for comment in response['items']\n",
    "        ]\n",
    "        comments = np.append(comments, comments_in_video)\n",
    "        \n",
    "        while response:   \n",
    "            comments_in_video = [\n",
    "                comment['snippet']['topLevelComment']['snippet']['textOriginal']\n",
    "                for comment in response['items']\n",
    "            ]\n",
    "            comments = np.append(comments, comments_in_video)\n",
    "            \n",
    "            if 'nextPageToken' in response:\n",
    "                request = youtube.commentThreads().list(\n",
    "                    part='snippet,replies',\n",
    "                    videoId=video_id,\n",
    "                    order = 'time',\n",
    "                    maxResults = 100,\n",
    "                    pageToken=response['nextPageToken']\n",
    "                )\n",
    "                response = request.execute()\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "            if len(set(comments)) > 2000:\n",
    "                break\n",
    "                \n",
    "    return list(set(comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "fa8a5ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processes and tokenizes the text\n",
    "def process_text(text): \n",
    "    out = re.sub(r'[^\\w\\s]', '', text) # Removing Punctuation\n",
    "    out = [word for word in out.split() if word.lower() not in stopwords.words('english')] # Removes Stopwords\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "97ba50be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting upload playlist from channel_id\n",
    "channel_ids = [\n",
    "    'UCX6OQ3DkcsbYNE6H8uQQuVA', # MrBeast\n",
    "    'UCoOjH8D2XAgjzQlneM2W0EQ', # JakeTran\n",
    "    'UCgv4dPk_qZNAbUW9WkuLPSA', # Atrioc\n",
    "    'UCYzPXprvl5Y-Sf0g4vX-m6g', # Jacksepticeye\n",
    "    'UCBJycsmduvYEL83R_U4JriQ'  # Marques Brownlee\n",
    "]\n",
    "playlists = get_playlists(youtube, channel_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "36f23e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all video ids for each Youtuber\n",
    "jacksepticeye_video_ids = get_video_ids(youtube, playlists[0])\n",
    "mr_beast_video_ids = get_video_ids(youtube, playlists[1])\n",
    "marques_brownlee_video_ids = get_video_ids(youtube, playlists[2])\n",
    "jake_tran_video_ids = get_video_ids(youtube, playlists[3])\n",
    "atrioc_video_ids = get_video_ids(youtube, playlists[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "0c2bb583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Jacksepticeye Videos:  4979\n",
      "Number of MrBeast Videos:  723\n",
      "Number of Marques Brownlee Videos:  1449\n",
      "Number of Jake Tran Videos:  203\n",
      "Number of Atrioc Videos:  615\n"
     ]
    }
   ],
   "source": [
    "# Number of videos for each Youtuber\n",
    "print('Number of Jacksepticeye Videos: ', len(jacksepticeye_video_ids))\n",
    "print('Number of MrBeast Videos: ', len(mr_beast_video_ids))\n",
    "print('Number of Marques Brownlee Videos: ', len(marques_brownlee_video_ids))\n",
    "print('Number of Jake Tran Videos: ', len(jake_tran_video_ids))\n",
    "print('Number of Atrioc Videos: ', len(atrioc_video_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "id": "b6f23c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only getting roughly at most 2000 comments from Youtuber's Latest Video\n",
    "jacksepticeye_comments = get_comments_in_videos(youtube, [jacksepticeye_video_ids[0]])\n",
    "mr_beast_comments = get_comments_in_videos(youtube, [mr_beast_video_ids[0]])\n",
    "marques_brownlee_comments = get_comments_in_videos(youtube, [marques_brownlee_video_ids[0]])\n",
    "jake_tran_comments = get_comments_in_videos(youtube, [jake_tran_video_ids[1]])\n",
    "atrioc_comments = get_comments_in_videos(youtube, [atrioc_video_ids[1]])\n",
    "# At the time, Jake Tran and Atrioc's Latest Video just came out so decided to use second latest video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "id": "59bd5f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combing all comments\n",
    "combined_comments = (\n",
    "    jacksepticeye_comments +\n",
    "    mr_beast_comments + \n",
    "    marques_brownlee_comments + \n",
    "    jake_tran_comments +\n",
    "    atrioc_comments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "f0e1e1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cats can eat grass it helps them when there st...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can't wait for Part 2 on this :D look's awes...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Its okay about the poncho Jack, you return to ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jack you forgot to find the first few memory s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I really hope Jack plays Sky some day, I reall...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7982</th>\n",
       "      <td>Forgot Paper Mario, classic mistake</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7983</th>\n",
       "      <td>what?!?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7984</th>\n",
       "      <td>I was not ready for him stabbing himself</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7985</th>\n",
       "      <td>I love the sound of falling onto a window in M...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7986</th>\n",
       "      <td>Fallout NV gotta be my GOAT game if i really h...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7987 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  is_spam\n",
       "0     Cats can eat grass it helps them when there st...      NaN\n",
       "1     I can't wait for Part 2 on this :D look's awes...      NaN\n",
       "2     Its okay about the poncho Jack, you return to ...      NaN\n",
       "3     Jack you forgot to find the first few memory s...      NaN\n",
       "4     I really hope Jack plays Sky some day, I reall...      NaN\n",
       "...                                                 ...      ...\n",
       "7982                Forgot Paper Mario, classic mistake      NaN\n",
       "7983                                            what?!?      NaN\n",
       "7984           I was not ready for him stabbing himself      NaN\n",
       "7985  I love the sound of falling onto a window in M...      NaN\n",
       "7986  Fallout NV gotta be my GOAT game if i really h...      NaN\n",
       "\n",
       "[7987 rows x 2 columns]"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial Setup of Comments DataFrame\n",
    "youtube_comments = pd.DataFrame(\n",
    "    data = {'comment': combined_comments, 'is_spam': [np.nan for i in range(len(combined_comments))]}\n",
    ")\n",
    "youtube_comments.to_csv('youtube_comments.csv', index = False)\n",
    "youtube_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "6b3e4b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ammogabs blog\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SO CLOSE TO 100M!\n",
      "0\n",
      "9:05\n",
      "0\n",
      "Guess what I shaved my head to weeks agai and I’m now just seeing this\n",
      "0\n",
      "100M SUSCRIPTORES SUSCRIBE A MRBEAST 🙏😈🤙😊😊\n",
      "0\n",
      "I'm that guy.\n",
      "0\n",
      "عقبال 100مليون مستر بيست انا انتظر ان اوفيك ال100مليون بنفسي مستر بيستIlove♥♥♥\n",
      "2\n",
      "Can we have one thousand to pay off a canon camrea\n",
      "0\n",
      "Today is my birthday:)\n",
      "0\n",
      "18\n",
      "0\n",
      "Jimmy, your taking this to far\n",
      "0\n",
      "It's so cool, because you can kinda see the behind the scenes of Jimmy's life lol\n",
      "0\n",
      "What you’re saying is that you used to come and see your family\n",
      "0\n",
      "Visit me\n",
      "0\n",
      "day one of asking for money i need 1000$ to get a new dirt bike\n",
      "1\n",
      "😎👍👍👍👍👍\n",
      "0\n",
      "Is this a world record\n",
      "0\n",
      "That surfing pikachu hoodie was so cool\n",
      "0\n",
      "Of you go too my birthday I will give you food ☺️\n",
      "0\n",
      "the odds of being picked fora vid is so rare i will never get to meet you im subbed\n",
      "0\n",
      "You should buy a private island and make a micro nation (boost this so he can see)\n",
      "0\n",
      "Cmon pepple subscribe we are almost at 100m\n",
      "0\n",
      "Subscribe to mrbeast the king himself I will kidnap you if you don’t 🥱 watch out fam\n",
      "0\n",
      "i donated superchats to u when u did ur fidget spinner streams and well u were rude to me so i dont rlly watch ur videos that much anymore\n",
      "0\n",
      "This is me\n",
      "0\n",
      "i dont want to try that but congrats no matter what for trying\n",
      "0\n",
      "Hey mr beast you can play roblox?\n",
      "0\n",
      "hi do i deserve subscribe?🥲😭\n",
      "0\n",
      "No way he can survive 30 days without food\n",
      "0\n",
      "I thought Chandler leave mrbeast crew\n",
      "0\n",
      "Why is Chris an emo now?\n",
      "0\n",
      "Who is visiting his profile till he hits 100m!! \n",
      " I'm visiting everyday I'm so excited and happy for him.\n",
      "0\n",
      "best 👍💖💖\n",
      "0\n",
      "tbh mrbeast fell off\n",
      "0\n",
      "I love jimmy\n",
      "0\n",
      "Subelo en tu canal en español please\n",
      "2\n",
      "Is chris okay?\n",
      "0\n",
      "How the hell did I just realize he is only 1m away from 100m\n",
      "0\n",
      "Can't wait for the cruise with one hundred people, it's going to be LIT\n",
      "0\n",
      "I show speed is about to pass you he coming to a billion\n",
      "0\n",
      "This man look better shaved lol\n",
      "0\n",
      "Hello mrbeast a question you. come to visit Nicaragua?\n",
      "0\n",
      "i remember when you had a gong idea by technoblade\n",
      "0\n",
      "Heeeel nou inglés\n",
      "2\n",
      "Can you give give away a hundred thousand dollars\n",
      "1\n",
      "you're my fave! 🇵🇭\n",
      "0\n",
      "32\n",
      "0\n",
      "WHERE ARE THE NEW VIDEOS 😒\n",
      "0\n",
      "Bald Craft no\n",
      "Bald beast yes\n",
      "0\n",
      "Your friends are hilarious 😂\n",
      "0\n",
      "hola mr beast de republica dominicana\n",
      "2\n",
      "❤️‍🩹❤️‍🩹❤️‍🩹\n",
      "0\n",
      "mr beast you no tecnoblad haz died\n",
      "0\n",
      "That's the spirit!\n",
      "0\n",
      "YO MISTA BEAST i have sent you  letter in a red envelope i ask you to invite me to challange so i can destroy them noobs my name is marco caldwell i request i challenge AND I WILL WIN MARCO CALDWELL SIGHNING OFF\n",
      "0\n",
      "You so close to 100m subscriber\n",
      "0\n",
      "mr beast I am a loyal subscriber for many months now but haven’t got any cookies 🥹\n",
      "0\n",
      "at this point its a christian ramadan because you cant eat\n",
      "0\n",
      "Hello Jimmy, i love your account and i wish you would come to Argentina, Buenos Aires and be able to participate in one of your videos\n",
      "0\n",
      "99 MILL LETS GOOOO BY THE END OF TODAY!!! 💘\n",
      "0\n",
      "You should plant a massive amount of solar panels!\n",
      "0\n",
      "send me a million dollars and I'll subscribe to your channel.\n",
      "1\n",
      "I hope the day comes I meet you\n",
      "0\n",
      "We’re is my cookie 🍪 it’s been 4 years\n",
      "0\n",
      "Me da um carro 😶\n",
      "2\n",
      "My dad met u in Vegas today and I’m very upset bc he just shook ur hand and left and he didn’t know who u were and now my sister and me are losing it bc we’ve been following u for a while😭\n",
      "0\n",
      "Mr beast I am a fan\n",
      "0\n",
      "if he can only drink water then buy the bottle with a smell that smells good to trick your taste\n",
      "0\n",
      "That's awesome\n",
      "0\n",
      "YESSSSSSS HE MADE A VID ABT HIMSELF😳\n",
      "0\n",
      "“Wait won’t u be hungry “ well no s*it Sherlock 🤣😂\n",
      "0\n",
      "🤣🤣🤣\n",
      "0\n",
      "1:57 ayo *UP* movie irl? 😳\n",
      "0\n",
      "What happened to Chris 😭\n",
      "0\n",
      "Ha you look better\n",
      "0\n",
      "Ничего не понятно но очень интересно\n",
      "2\n",
      "Hole\n",
      "0\n",
      "❤️❤️❤️\n",
      "0\n",
      "i weigh 110 pound\n",
      "0\n",
      "Jimmy you’re crazy…\n",
      "0\n",
      "Hi mrbeast I love your videos but this is her son I subscribed and put on all post notifications ty for making me feel better  every\n",
      "0\n",
      "Mrbeast did you now that tanendbld die\n",
      "0\n",
      "I liked and subscribed\n",
      "0\n",
      "Kiiiiiiiiiiing boooooooob!\n",
      "0\n",
      "SO CLOSE TO 100M!!!\n",
      "0\n",
      "Been here since 2018\n",
      "0\n",
      "Mccheesies\n",
      "0\n",
      "How is meatlover\n",
      "0\n",
      "I’d die doing this\n",
      "0\n",
      "Please go to Colorado Springs and help the homeless.\n",
      "0\n",
      "Bro I honestly love the bald it looks great\n",
      "0\n",
      "Subscribe to this man for practically starving himself so that we could be entertained!\n",
      "0\n",
      "لعبهم بالنعمة مستفز\n",
      "2\n",
      "29\n",
      "j\n"
     ]
    }
   ],
   "source": [
    "# Labeling Comments if Spam or Not\n",
    "youtube_comment_temp = pd.read_csv('youtube_comments.csv')\n",
    "for i in range(youtube_comments.shape[0]):\n",
    "    if np.isnan(youtube_comment_temp['is_spam'].iloc[i]):\n",
    "        print(youtube_comment_temp.iloc[i]['comment'])\n",
    "        is_spam = input()\n",
    "        if is_spam in ['0', '1']:\n",
    "            youtube_comment_temp['is_spam'].iloc[i] = is_spam\n",
    "        elif is_spam in ['2']:\n",
    "            youtube_comment_temp['is_spam'].iloc[i] = 2\n",
    "        else:\n",
    "            break\n",
    "youtube_comment_temp.to_csv('youtube_comments.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "550a42c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr beast, create the backrooms in real life</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mr. Beast is the world's famous as well as ide...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello sir \\nI am Sarvesh From India\\nI need 1k...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Only 1M please guys  you can do it</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i love you mrbeast😻😻</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10051</th>\n",
       "      <td>Bro i send some, direct message on your legit ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10052</th>\n",
       "      <td>Hi mr beast you are my favorite YouTuber</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10053</th>\n",
       "      <td>Where’s karl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10054</th>\n",
       "      <td>You basically got a haircut no need for a hat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10055</th>\n",
       "      <td>Cool</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10056 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  is_spam\n",
       "0            Mr beast, create the backrooms in real life      0.0\n",
       "1      Mr. Beast is the world's famous as well as ide...      0.0\n",
       "2      Hello sir \\nI am Sarvesh From India\\nI need 1k...      1.0\n",
       "3                     Only 1M please guys  you can do it      0.0\n",
       "4                                   i love you mrbeast😻😻      0.0\n",
       "...                                                  ...      ...\n",
       "10051  Bro i send some, direct message on your legit ...      NaN\n",
       "10052           Hi mr beast you are my favorite YouTuber      NaN\n",
       "10053                                       Where’s karl      NaN\n",
       "10054      You basically got a haircut no need for a hat      NaN\n",
       "10055                                               Cool      NaN\n",
       "\n",
       "[10056 rows x 2 columns]"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data = pd.read_csv('youtube_comments.csv')\n",
    "labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "80652798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "780"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of valid data\n",
    "sum(labeled_data['is_spam'] < 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "b9bb42cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of invalid data\n",
    "labeled_data[labeled_data['is_spam'] == 2].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "78e3518f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "710"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Not-Spam\n",
    "labeled_data[labeled_data['is_spam'] == 0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "e30e8aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Spam\n",
    "labeled_data[labeled_data['is_spam'] == 1].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6827bf",
   "metadata": {},
   "source": [
    "To get more data for spam comments, I utilized the UCI Machine Learning Repository to gather more spam comments.\n",
    "https://archive.ics.uci.edu/ml/datasets/YouTube+Spam+Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "6165e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data from UCI Machine Learning Repository\n",
    "psy_data = pd.read_csv('YouTube-Spam-Collection-v1/Youtube01-Psy.csv')[['CONTENT', 'CLASS']]\n",
    "katy_perry_data = pd.read_csv('YouTube-Spam-Collection-v1/Youtube02-KatyPerry.csv')[['CONTENT', 'CLASS']]\n",
    "lmfao_data = pd.read_csv('YouTube-Spam-Collection-v1/Youtube03-LMFAO.csv')[['CONTENT', 'CLASS']]\n",
    "eminem_data = pd.read_csv('YouTube-Spam-Collection-v1/Youtube04-Eminem.csv')[['CONTENT', 'CLASS']]\n",
    "shakira_data = pd.read_csv('YouTube-Spam-Collection-v1/Youtube05-Shakira.csv')[['CONTENT', 'CLASS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "1548e4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>********OMG Facebook is OLD! Check out  ------...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Hey Music Fans I really appreciate all of you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>**CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>**CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>**CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1005 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comments  is_spam\n",
       "0    Huh, anyway check out this you[tube] channel: ...        1\n",
       "1    Hey guys check out my new channel and our firs...        1\n",
       "2               just for test I have to say murdev.com        1\n",
       "3     me shaking my sexy ass on my channel enjoy ^_^ ﻿        1\n",
       "4              watch?v=vtaRGgvGtWQ   Check this out .﻿        1\n",
       "..                                                 ...      ...\n",
       "357  ********OMG Facebook is OLD! Check out  ------...        1\n",
       "358  Hey Music Fans I really appreciate all of you ...        1\n",
       "359  **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...        1\n",
       "360  **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...        1\n",
       "361  **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...        1\n",
       "\n",
       "[1005 rows x 2 columns]"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat all spam comments, standardizing column names, filter only spam comments\n",
    "spam_data = pd.concat([psy_data, katy_perry_data, lmfao_data, eminem_data, shakira_data])\n",
    "spam_comments = spam_data.rename(columns={'CONTENT':'comments', 'CLASS':'is_spam'})[spam_data['CLASS'] == 1]\n",
    "spam_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30279f2d",
   "metadata": {},
   "source": [
    "<h2>Creating Spam Detection ML Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "9de5bf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr beast, create the backrooms in real life</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mr. Beast is the world's famous as well as ide...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello sir \\nI am Sarvesh From India\\nI need 1k...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Only 1M please guys  you can do it</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i love you mrbeast😻😻</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>How is meatlover</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>I’d die doing this</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>Please go to Colorado Springs and help the hom...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>Bro I honestly love the bald it looks great</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>Subscribe to this man for practically starving...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment  is_spam\n",
       "0          Mr beast, create the backrooms in real life      0.0\n",
       "1    Mr. Beast is the world's famous as well as ide...      0.0\n",
       "2    Hello sir \\nI am Sarvesh From India\\nI need 1k...      1.0\n",
       "3                   Only 1M please guys  you can do it      0.0\n",
       "4                                 i love you mrbeast😻😻      0.0\n",
       "..                                                 ...      ...\n",
       "841                                   How is meatlover      0.0\n",
       "842                                 I’d die doing this      0.0\n",
       "843  Please go to Colorado Springs and help the hom...      0.0\n",
       "844        Bro I honestly love the bald it looks great      0.0\n",
       "845  Subscribe to this man for practically starving...      0.0\n",
       "\n",
       "[780 rows x 2 columns]"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = labeled_data[labeled_data['is_spam'] < 2]\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "8e499033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to matrix of token counts\n",
    "bag_of_words = CountVectorizer(analyzer=process_text).fit_transform(filtered_data['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "378ca7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    bag_of_words,\n",
    "    filtered_data['is_spam'],\n",
    "    test_size = 0.3,\n",
    "    random_state = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "863876fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and training Naive Bayes Classifier\n",
    "classifier = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e2f29e",
   "metadata": {},
   "source": [
    "<h2>Evaluating Model on Training Data Set</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "7b5dfdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99       501\n",
      "         1.0       1.00      0.73      0.85        45\n",
      "\n",
      "    accuracy                           0.98       546\n",
      "   macro avg       0.99      0.87      0.92       546\n",
      "weighted avg       0.98      0.98      0.98       546\n",
      "\n",
      "Confusion matrix: \n",
      " [[501   0]\n",
      " [ 12  33]] \n",
      "\n",
      "Accuracy: \n",
      " 0.978021978021978\n"
     ]
    }
   ],
   "source": [
    "pred_train = classifier.predict(X_train)\n",
    "print('Classification Report: \\n', classification_report(y_train, pred_train))\n",
    "print('Confusion matrix: \\n', confusion_matrix(y_train, pred_train), '\\n')\n",
    "print('Accuracy: \\n', accuracy_score(y_train, pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa6a02b",
   "metadata": {},
   "source": [
    "<h2>Evaluating Model on Test Data Set</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "16f1c888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.93      0.93       209\n",
      "         1.0       0.44      0.44      0.44        25\n",
      "\n",
      "    accuracy                           0.88       234\n",
      "   macro avg       0.69      0.69      0.69       234\n",
      "weighted avg       0.88      0.88      0.88       234\n",
      "\n",
      "Confusion matrix: \n",
      " [[195  14]\n",
      " [ 14  11]] \n",
      "\n",
      "Accuracy: \n",
      " 0.8803418803418803\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Model on training data set\n",
    "pred_test = classifier.predict(X_test)\n",
    "print('Classification Report: \\n', classification_report(y_test, pred_test))\n",
    "print('Confusion matrix: \\n', confusion_matrix(y_test, pred_test), '\\n')\n",
    "print('Accuracy: \\n', accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9df644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

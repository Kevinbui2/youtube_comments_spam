{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "399fef4e",
   "metadata": {},
   "source": [
    "<h1>Youtube Comments Spam Detection</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b1846c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdcec73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/kevin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading Stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "938a930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting api_key from environment variable\n",
    "load_dotenv()\n",
    "api_key = os.getenv('api_key')\n",
    "\n",
    "# Creating build object for Youtube\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "262d4145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_ids(youtube, playlist_id):\n",
    "    video_ids = []\n",
    "    \n",
    "    request = youtube.playlistItems().list(\n",
    "        part='contentDetails',\n",
    "        playlistId=playlist_id,\n",
    "        maxResults = 50\n",
    "    )\n",
    "    \n",
    "    response = request.execute()\n",
    "    \n",
    "    for item in response['items']:\n",
    "        video_ids.append(item['contentDetails']['videoId'])\n",
    "        \n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    \n",
    "    while next_page_token is not None:\n",
    "        request = youtube.playlistItems().list(\n",
    "            part='contentDetails',\n",
    "            playlistId = playlist_id,\n",
    "            maxResults = 50,\n",
    "            pageToken = next_page_token\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        for item in response['items']:\n",
    "            video_ids.append(item['contentDetails']['videoId'])\n",
    "            \n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        \n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b982c6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlists(youtube, channel_ids):\n",
    "    upload_playlists = []\n",
    "    \n",
    "    request = youtube.channels().list(\n",
    "        part='contentDetails',\n",
    "        id=','.join(channel_ids)\n",
    "    )\n",
    "    \n",
    "    response = request.execute()\n",
    "    \n",
    "    for item in response['items']:\n",
    "        upload_playlists.append(item['contentDetails']['relatedPlaylists']['uploads'])\n",
    "        \n",
    "    return upload_playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e969165e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments_in_videos(youtube, video_ids):\n",
    "    comments = np.array([])\n",
    "    \n",
    "    for video_id in video_ids:\n",
    "        request = youtube.commentThreads().list(\n",
    "            part='snippet,replies',\n",
    "            videoId=video_id,\n",
    "            order = 'time',\n",
    "            maxResults = 100\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        comments_in_video = [\n",
    "            comment['snippet']['topLevelComment']['snippet']['textOriginal']\n",
    "            for comment in response['items']\n",
    "        ]\n",
    "        comments = np.append(comments, comments_in_video)\n",
    "        \n",
    "        while response:   \n",
    "            comments_in_video = [\n",
    "                comment['snippet']['topLevelComment']['snippet']['textOriginal']\n",
    "                for comment in response['items']\n",
    "            ]\n",
    "            comments = np.append(comments, comments_in_video)\n",
    "            \n",
    "            if 'nextPageToken' in response:\n",
    "                request = youtube.commentThreads().list(\n",
    "                    part='snippet,replies',\n",
    "                    videoId=video_id,\n",
    "                    order = 'time',\n",
    "                    maxResults = 100,\n",
    "                    pageToken=response['nextPageToken']\n",
    "                )\n",
    "                response = request.execute()\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "            if len(set(comments)) > 2000:\n",
    "                break\n",
    "                \n",
    "    return list(set(comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa8a5ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processes and tokenizes the text\n",
    "def process_text(text): \n",
    "    out = re.sub(r'[^\\w\\s]', '', text) # Removing Punctuation\n",
    "    out = [word for word in out.split() if word.lower() not in stopwords.words('english')] # Removes Stopwords\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "97ba50be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting upload playlist from channel_id\n",
    "channel_ids = [\n",
    "    'UCX6OQ3DkcsbYNE6H8uQQuVA', # MrBeast\n",
    "    'UCoOjH8D2XAgjzQlneM2W0EQ', # JakeTran\n",
    "    'UCgv4dPk_qZNAbUW9WkuLPSA', # Atrioc\n",
    "    'UCYzPXprvl5Y-Sf0g4vX-m6g', # Jacksepticeye\n",
    "    'UCBJycsmduvYEL83R_U4JriQ'  # Marques Brownlee\n",
    "]\n",
    "playlists = get_playlists(youtube, channel_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "0a80acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all video ids for each Youtuber\n",
    "jacksepticeye_video_ids = get_video_ids(youtube, playlists[0])\n",
    "mr_beast_video_ids = get_video_ids(youtube, playlists[1])\n",
    "marques_brownlee_video_ids = get_video_ids(youtube, playlists[2])\n",
    "jake_tran_video_ids = get_video_ids(youtube, playlists[3])\n",
    "atrioc_video_ids = get_video_ids(youtube, playlists[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "6f210e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Jacksepticeye Videos:  4979\n",
      "Number of MrBeast Videos:  723\n",
      "Number of Marques Brownlee Videos:  1449\n",
      "Number of Jake Tran Videos:  203\n",
      "Number of Atrioc Videos:  615\n"
     ]
    }
   ],
   "source": [
    "# Number of videos for each Youtuber\n",
    "print('Number of Jacksepticeye Videos: ', len(jacksepticeye_video_ids))\n",
    "print('Number of MrBeast Videos: ', len(mr_beast_video_ids))\n",
    "print('Number of Marques Brownlee Videos: ', len(marques_brownlee_video_ids))\n",
    "print('Number of Jake Tran Videos: ', len(jake_tran_video_ids))\n",
    "print('Number of Atrioc Videos: ', len(atrioc_video_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "id": "b6f23c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only getting roughly at most 2000 comments from Youtuber's Latest Video\n",
    "jacksepticeye_comments = get_comments_in_videos(youtube, [jacksepticeye_video_ids[0]])\n",
    "mr_beast_comments = get_comments_in_videos(youtube, [mr_beast_video_ids[0]])\n",
    "marques_brownlee_comments = get_comments_in_videos(youtube, [marques_brownlee_video_ids[0]])\n",
    "jake_tran_comments = get_comments_in_videos(youtube, [jake_tran_video_ids[1]])\n",
    "atrioc_comments = get_comments_in_videos(youtube, [atrioc_video_ids[1]])\n",
    "# At the time, Jake Tran and Atrioc's Latest Video just came out so decided to use second latest video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "id": "e8c928fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combing all comments\n",
    "combined_comments = (\n",
    "    jacksepticeye_comments +\n",
    "    mr_beast_comments + \n",
    "    marques_brownlee_comments + \n",
    "    jake_tran_comments +\n",
    "    atrioc_comments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "f0e1e1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cats can eat grass it helps them when there st...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can't wait for Part 2 on this :D look's awes...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Its okay about the poncho Jack, you return to ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jack you forgot to find the first few memory s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I really hope Jack plays Sky some day, I reall...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7982</th>\n",
       "      <td>Forgot Paper Mario, classic mistake</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7983</th>\n",
       "      <td>what?!?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7984</th>\n",
       "      <td>I was not ready for him stabbing himself</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7985</th>\n",
       "      <td>I love the sound of falling onto a window in M...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7986</th>\n",
       "      <td>Fallout NV gotta be my GOAT game if i really h...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7987 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  is_spam\n",
       "0     Cats can eat grass it helps them when there st...      NaN\n",
       "1     I can't wait for Part 2 on this :D look's awes...      NaN\n",
       "2     Its okay about the poncho Jack, you return to ...      NaN\n",
       "3     Jack you forgot to find the first few memory s...      NaN\n",
       "4     I really hope Jack plays Sky some day, I reall...      NaN\n",
       "...                                                 ...      ...\n",
       "7982                Forgot Paper Mario, classic mistake      NaN\n",
       "7983                                            what?!?      NaN\n",
       "7984           I was not ready for him stabbing himself      NaN\n",
       "7985  I love the sound of falling onto a window in M...      NaN\n",
       "7986  Fallout NV gotta be my GOAT game if i really h...      NaN\n",
       "\n",
       "[7987 rows x 2 columns]"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial Setup of Comments DataFrame\n",
    "#youtube_comments = pd.DataFrame(\n",
    "#    data = {'comment': combined_comments, 'is_spam': [np.nan for i in range(len(combined_comments))]}\n",
    "#)\n",
    "#youtube_comments.to_csv('youtube_comments.csv', index = False)\n",
    "#youtube_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e4b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eh, Internet Historian did it first and did it better.\n",
      "0\n",
      "I know scaming is wrong but how do you get scammed this hard\n",
      "0\n",
      "*https://youtu.be/mCfYi7634rU*\n",
      "Finally its here.\n",
      "1\n",
      "Stop the camera clicking sound it is way to loud and please go back to voicing your own videos this guy you have now is garbage and way too aggressive\n",
      "0\n",
      "Third\n",
      "0\n",
      "Ignorant! can‚Äôt even spell Colombia lmao\n",
      "0\n",
      "üëå\n",
      "0\n",
      "so those artists are thieves?\n",
      "0\n",
      "He should have just cancelled the whole thing and cut his losses after the $20M investment failed to push through. That would have caused the least amount of inconvenience for everyone involved.\n",
      "0\n",
      "To be honest he was really almost close enough. The video puts it like the experience of the guests was supposed to be the priority but it never was. It was the content people can produce while being there having paid that much. Just had to make the food and the sleeping conditions look good on photos smh and it would work I'm convinced\n",
      "0\n",
      "This channel has gone to the dogs, guy doesn't give a rats ass about quality assurance any more.\n",
      "0\n",
      "imagine getting standed in a  island and then  it turns into a battle royale .\n",
      "0\n",
      "Imagine that sucks for everyone involved but if u down to drop that much on a festival than jokes on u\n",
      "0\n",
      "we NEEEEED a video on andrew tate\n",
      "0\n",
      "\"I will never ask you for money or ask you to invest in anything\" he says then does an AD all about investing your money..... Hmm.. Then I will take your advice and NEVER look into your supported ads.\n",
      "0\n",
      "Still trying to figure out if this was an outright scam or if this guy just really sucked at putting on festivals?\n",
      "0\n",
      "I‚Äôd you‚Äôre willing to pay 12k to see a show, you deserve to lose your money.\n",
      "0\n",
      "17:09 effry jeipsten\n",
      "0\n",
      "I suddenly miss Internet Historian. I learned of this from his vid\n",
      "0\n",
      "I‚Äôm surprised this video had so few spelling mistakes. The people making your videos stopped eating crayons and actually used a spell checker?\n",
      "0\n",
      "Your videos are amazing man. I love listening to them while I work, it makes the time fly AND I learn something. So, thank you.\n",
      "0\n",
      "America is the devil in design ü§´\n",
      "0\n",
      "Indian fansüëç\n",
      "0\n",
      "When creators say \"competition\" or \"giveaway\"... Oh word...you mean buying followers ü§¶‚Äç‚ôÇÔ∏è just say \"if you follow me I'll pay you\"\n",
      "0\n",
      "Nice title, this will get people to stop saying you're helping scammers üòÜ  , I'm j.k I just remember the latest videos comments haha\n",
      "0\n",
      "These filthy rich pop culture influencer followers get what they needed (maybe even what they deserved for some of them): a reality check.\n",
      "0\n",
      "26m usd and he can't make it happen?\n",
      "0\n",
      "Is anyone actually asking their refunds? \n",
      "\n",
      "I‚Äôm curious if the YouTuber talking about scams is running one‚Ä¶ i love his videos and want to believe so bad but it‚Äôs hard to believe anything now a days. Someone reassure me üòÖüòÖ\n",
      "\n",
      "#freepalestine ‚ù§\n",
      "0\n",
      "Someone's running out of ideas\n",
      "0\n",
      "this video made me want to unsubscribe\n",
      "0\n",
      "Cheese sandwich. Gets me laughing everytime.\n",
      "0\n",
      "Lmfao the poor elite got scammed üòÇ\n",
      "0\n",
      "Find it really ironic how you make videos criticising bad people and yet 5 minutes into the video you start promoting a service completely centred around people gambling with their pensions\n",
      "0\n",
      "Wallenberg family please\n",
      "0\n",
      "Makes me want to watch some Hulu or Netflix.\n",
      "0\n",
      "Aww poor rich kids did things not go how you wanted for the first time ever? Welcome to the other side üñï\n",
      "0\n",
      "I'm a fan of this channel.......but, whinge, whinge, whinge, whinge, whinge ü§£\n",
      "0\n",
      "60k, I bet Mr. Beast could pull this off if he wanted to.\n",
      "0\n",
      "When you name your crypto firm \"I Trust Capital\", it makes it quite hard to believe any amount of capital will be safe in your hands. And, any viewer gullible enough to open an account with a company that has that sketchy of a name also probably thinks Jake Tran isn't a hypocrite, and would never use _principally identical_ tactics as the shady people he preaches about on here\n",
      "0\n",
      "ok.....\n",
      "0\n",
      "Imagine being consistently high jacked for the carbs u earn only to have little to no one to fight for your consumer rights. \n",
      "\n",
      "Every Single American üò©\n",
      "0\n",
      "I think a series on Netflix was inspired from such incident\n",
      "0\n",
      "FOR THE LOVE OF GOD PLSSSSS STOP PLUGGING YOUR CHANEL membership I get it man just tell the story straightforward and stop adding fluff\n",
      "0\n",
      "Jake, voice.. is just bad. Just do this by yourself.\n",
      "0\n",
      "Good concept bad execution. If he had 3 years of planning before the actual festival it would have worked.\n",
      "0\n",
      "Oh i remember this I have no clue how they got away with this probably just because the influencers\n",
      "0\n",
      "DuDE Jake! ...Create some new content man ...most of your stuffs these days are just recycled documentaries ..IV SEEEN THEM BEFORE from other people!!!!\n",
      "0\n",
      "Fyre actually did happen... What was promised was delivered to the ones making the advert.\n",
      "0\n",
      "I'm surprised that just showing, \"Mr. I didn't do myself in.\", doesn't get this video kicked these days.\n",
      "0\n",
      "Your videos are always the same, some businessman is enslaving a country, and the thumbnails won‚Äôt change\n",
      "0\n",
      "Been waiting for you to do this video! Haha loved it Jake!\n",
      "0\n",
      "I‚Äôm technically the first comment after Jake\n",
      "0\n",
      "The new wave of titles sucks ass. This narrator guy's storytelling is dull and¬†boring\n",
      "0\n",
      "Clickbait title not related to subject. No description at all that describes the subject..\n",
      "0\n",
      "Lmao buy crypto because it's a dip. It's crashing because it's a scam\n",
      "0\n",
      "lol, rich kids who (most of them but I'm sure not all of them) burnt money they didnt earn and got sad about being scammed....\n",
      "0\n",
      "I want to watch your videos but they're SO click batie\n",
      "0\n",
      "Runing out of content from wiki? Last few videos is stuff we all heard a thousand times\n",
      "0\n",
      "Crazy how ja rule got off Scott free, money hey\n",
      "0\n",
      "The biggest news no one is talking about https://youtu.be/YilL9f4O47M\n",
      "1\n",
      "If this actually happened like it was supposed too it would be amazing. It was a shame what happened.\n",
      "0\n",
      "Lmfao, I'm glad these dumb fks got scammed\n",
      "0\n",
      "Jake finally selling out. Pushing crypto scams and using others for the voiceover. Shame, it‚Äôs been fun but I‚Äôm out.\n",
      "0\n",
      "I would have just got a big tent\n",
      "0\n",
      "Never got the square lol\n",
      "0\n",
      "‚ÄúEffery Jepstein‚Äù\n",
      "0\n",
      "DONT TRUST THE SPONSOR, ALL THE CRYPTO BANKS ARE FALLING RN, AND YOUR WALLETS WILL BE FROZEN\n",
      "0\n",
      "His videos these days either have the clickbaity titles or it is \"fear-mongering\" the viewers about the topic of the video. Try to keep the title more neutral instead of using strong words.\n",
      "0\n",
      "This is the Cayo Perico DLC from GTA Online\n",
      "0\n",
      "@Jake Tran I love this one,lolzzzz\n",
      "0\n",
      "the only victims were the workers, everyone else got what they deserved\n",
      "0\n",
      "Every festival is a crap show especially for the performers. I‚Äôve been involved and it‚Äôs always like this.\n",
      "0\n",
      "This whole story will never not be funny AF.\n",
      "0\n",
      "Nope, Jake is still not narrating his own videos.\n",
      "0\n",
      "Netflix also has a great documentary on it, but this one is next level\n",
      "0\n",
      "Is it just me or is the new guy saying \"Effery Jepstein\" ...?\n",
      "\n",
      " I'm pretty sure its \"Jeffery Epstein\" üòÇ\n",
      "0\n",
      "\"The storm turned all of the marketing....into lies.\"\n",
      "0\n",
      "Literally watched the Netflix docu-movie on Fyre Fest yesterday, crazy how insane the behind the scenes were.\n",
      "0\n",
      "Damn I've never even heard of this lmao\n",
      "0\n",
      "Maxwell is the only person charged with sex trafficking minors to no one\n",
      "0\n",
      "17:32 The infamous \"Effry Jepsein\"\n",
      "0\n",
      "I read a article about this fool in the video.\n",
      "0\n",
      "*Your videos are always the best do receive a notification each time you post a new video.. We'll have regrets for things we did not participate in..Investment should always be on any creative man's heart for success in life.*\n",
      "0\n",
      "Not everyone‚Äôs feed. Someone of us didn‚Äôt follow these basic wyt girls\n",
      "0\n",
      "Only by the thumbnail we know what this is\n",
      "0\n",
      "My new favorite part about Jake videos is reading all the hate lmao fuck this channel\n",
      "0\n",
      "Kinda ironic the sponsor is called iTrustCapital considering the nature of this channel. Nice videos though.\n",
      "\n",
      "\n",
      "\n",
      "TOP GUN 2 MAVERICK | Ending Dogfight Battle https://youtu.be/dx6AsbuRixw\n",
      "INTERSTELLAR Main Theme Guitar https://youtu.be/xfB4Ez9IaI0\n",
      "Killing Arasaka... | Cyberpunk 2077 Rebel Path Guitar MV https://youtu.be/X3_JrXwr4k0\n"
     ]
    }
   ],
   "source": [
    "# Labeling Comments if Spam or Not\n",
    "youtube_comment_temp = pd.read_csv('youtube_comments.csv')\n",
    "for i in range(youtube_comment_temp.shape[0]):\n",
    "    if np.isnan(youtube_comment_temp['is_spam'].iloc[i]):\n",
    "        print(youtube_comment_temp.iloc[i]['comment'])\n",
    "        is_spam = input()\n",
    "        if is_spam in ['0', '1']:\n",
    "            youtube_comment_temp['is_spam'].iloc[i] = is_spam\n",
    "        elif is_spam in ['2']:\n",
    "            youtube_comment_temp['is_spam'].iloc[i] = 2\n",
    "        else:\n",
    "            break\n",
    "youtube_comment_temp.to_csv('youtube_comments.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "550a42c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cats can eat grass it helps them when there st...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can't wait for Part 2 on this :D look's awes...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Its okay about the poncho Jack, you return to ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jack you forgot to find the first few memory s...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I really hope Jack plays Sky some day, I reall...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7983</th>\n",
       "      <td>Forgot Paper Mario, classic mistake</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7984</th>\n",
       "      <td>what?!?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7985</th>\n",
       "      <td>I was not ready for him stabbing himself</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7986</th>\n",
       "      <td>I love the sound of falling onto a window in M...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7987</th>\n",
       "      <td>Fallout NV gotta be my GOAT game if i really h...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7988 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  is_spam\n",
       "0     Cats can eat grass it helps them when there st...      0.0\n",
       "1     I can't wait for Part 2 on this :D look's awes...      0.0\n",
       "2     Its okay about the poncho Jack, you return to ...      0.0\n",
       "3     Jack you forgot to find the first few memory s...      0.0\n",
       "4     I really hope Jack plays Sky some day, I reall...      0.0\n",
       "...                                                 ...      ...\n",
       "7983                Forgot Paper Mario, classic mistake      NaN\n",
       "7984                                            what?!?      NaN\n",
       "7985           I was not ready for him stabbing himself      NaN\n",
       "7986  I love the sound of falling onto a window in M...      NaN\n",
       "7987  Fallout NV gotta be my GOAT game if i really h...      NaN\n",
       "\n",
       "[7988 rows x 2 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data = pd.read_csv('youtube_comments.csv')\n",
    "labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "80652798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6124"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of valid data\n",
    "sum(labeled_data['is_spam'] < 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "b9bb42cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of \"invalid\" data, where invalid is gibberish or non-english\n",
    "labeled_data[labeled_data['is_spam'] == 2].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "78e3518f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5844"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Not-Spam\n",
    "labeled_data[labeled_data['is_spam'] == 0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e30e8aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Spam\n",
    "labeled_data[labeled_data['is_spam'] == 1].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfd8611",
   "metadata": {},
   "source": [
    "To get more data for spam comments, I utilized the UCI Machine Learning Repository to gather more spam comments.\n",
    "https://archive.ics.uci.edu/ml/datasets/YouTube+Spam+Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0ec902b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data from UCI Machine Learning Repository\n",
    "psy_data = pd.read_csv('YouTube-Spam-Collection-v1/Youtube01-Psy.csv')[['CONTENT', 'CLASS']]\n",
    "katy_perry_data = pd.read_csv('YouTube-Spam-Collection-v1/Youtube02-KatyPerry.csv')[['CONTENT', 'CLASS']]\n",
    "lmfao_data = pd.read_csv('YouTube-Spam-Collection-v1/Youtube03-LMFAO.csv')[['CONTENT', 'CLASS']]\n",
    "eminem_data = pd.read_csv('YouTube-Spam-Collection-v1/Youtube04-Eminem.csv')[['CONTENT', 'CLASS']]\n",
    "shakira_data = pd.read_csv('YouTube-Spam-Collection-v1/Youtube05-Shakira.csv')[['CONTENT', 'CLASS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b39b6278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ Ôªø</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .Ôªø</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>********OMG Facebook is OLD! Check out  ------...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Hey Music Fans I really appreciate all of you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>**CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>**CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>**CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1005 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment  is_spam\n",
       "0    Huh, anyway check out this you[tube] channel: ...        1\n",
       "1    Hey guys check out my new channel and our firs...        1\n",
       "2               just for test I have to say murdev.com        1\n",
       "3     me shaking my sexy ass on my channel enjoy ^_^ Ôªø        1\n",
       "4              watch?v=vtaRGgvGtWQ   Check this out .Ôªø        1\n",
       "..                                                 ...      ...\n",
       "357  ********OMG Facebook is OLD! Check out  ------...        1\n",
       "358  Hey Music Fans I really appreciate all of you ...        1\n",
       "359  **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...        1\n",
       "360  **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...        1\n",
       "361  **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...        1\n",
       "\n",
       "[1005 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat all spam comments, standardizing column names, filter only spam comments\n",
    "spam_data = pd.concat([psy_data, katy_perry_data, lmfao_data, eminem_data, shakira_data])\n",
    "spam_comments = spam_data.rename(columns={'CONTENT':'comment', 'CLASS':'is_spam'})[spam_data['CLASS'] == 1]\n",
    "spam_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30279f2d",
   "metadata": {},
   "source": [
    "<h2>Creating Spam Detection ML Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9de5bf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cats can eat grass it helps them when there st...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can't wait for Part 2 on this :D look's awes...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Its okay about the poncho Jack, you return to ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jack you forgot to find the first few memory s...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I really hope Jack plays Sky some day, I reall...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>********OMG Facebook is OLD! Check out  ------...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Hey Music Fans I really appreciate all of you ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>**CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>**CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>**CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4065 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment  is_spam\n",
       "0    Cats can eat grass it helps them when there st...      0.0\n",
       "1    I can't wait for Part 2 on this :D look's awes...      0.0\n",
       "2    Its okay about the poncho Jack, you return to ...      0.0\n",
       "3    Jack you forgot to find the first few memory s...      0.0\n",
       "4    I really hope Jack plays Sky some day, I reall...      0.0\n",
       "..                                                 ...      ...\n",
       "357  ********OMG Facebook is OLD! Check out  ------...      1.0\n",
       "358  Hey Music Fans I really appreciate all of you ...      1.0\n",
       "359  **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...      1.0\n",
       "360  **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...      1.0\n",
       "361  **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...      1.0\n",
       "\n",
       "[4065 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = pd.concat([labeled_data[labeled_data['is_spam'] < 2], spam_comments]).dropna()\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8e499033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to matrix of token counts\n",
    "bag_of_words = CountVectorizer(analyzer=process_text).fit_transform(filtered_data['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "378ca7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    bag_of_words,\n",
    "    filtered_data['is_spam'],\n",
    "    test_size = 0.3,\n",
    "    random_state = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "863876fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and training Naive Bayes Classifier\n",
    "classifier = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e2f29e",
   "metadata": {},
   "source": [
    "<h2>Evaluating Model on Training Data Set</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7b5dfdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      2069\n",
      "         1.0       0.96      0.98      0.97       776\n",
      "\n",
      "    accuracy                           0.98      2845\n",
      "   macro avg       0.97      0.98      0.98      2845\n",
      "weighted avg       0.98      0.98      0.98      2845\n",
      "\n",
      "Confusion matrix: \n",
      " [[2034   35]\n",
      " [  15  761]] \n",
      "\n",
      "Accuracy: \n",
      " 0.9824253075571178\n"
     ]
    }
   ],
   "source": [
    "pred_train = classifier.predict(X_train)\n",
    "print('Classification Report: \\n', classification_report(y_train, pred_train))\n",
    "print('Confusion matrix: \\n', confusion_matrix(y_train, pred_train), '\\n')\n",
    "print('Accuracy: \\n', accuracy_score(y_train, pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa6a02b",
   "metadata": {},
   "source": [
    "<h2>Evaluating Model on Test Data Set</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "16f1c888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.95       882\n",
      "         1.0       0.87      0.85      0.86       338\n",
      "\n",
      "    accuracy                           0.92      1220\n",
      "   macro avg       0.91      0.90      0.90      1220\n",
      "weighted avg       0.92      0.92      0.92      1220\n",
      "\n",
      "Confusion matrix: \n",
      " [[840  42]\n",
      " [ 52 286]] \n",
      "\n",
      "Accuracy: \n",
      " 0.9229508196721311\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Model on training data set\n",
    "pred_test = classifier.predict(X_test)\n",
    "print('Classification Report: \\n', classification_report(y_test, pred_test))\n",
    "print('Confusion matrix: \\n', confusion_matrix(y_test, pred_test), '\\n')\n",
    "print('Accuracy: \\n', accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9df644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
